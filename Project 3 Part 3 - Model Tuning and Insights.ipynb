{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "Done by: Goh Chun Shan, DSIF 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of project notebooks:\n",
    "\n",
    "1 - Project Overview and Data Acquisition through Webscraping\n",
    "\n",
    "2 - Exploratory Data Analysis\n",
    "\n",
    "**3 - Model Tuning and Insights** (current notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this notebook, the subreddits that each post is from is denoted as binary where: Social Anxiety is 1, OCD is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline #can try to explore make_pipeline, don't have to write so much\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in files\n",
    "df_combined = pd.read_csv('data\\combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>fulltextlength</th>\n",
       "      <th>selftextlength</th>\n",
       "      <th>titlelength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'll go first, I'm 28F. I have a lot of childh...</td>\n",
       "      <td>What are your most disturbing/ disgusting intr...</td>\n",
       "      <td>yy5m0e</td>\n",
       "      <td>What are your most disturbing/ disgusting intr...</td>\n",
       "      <td>1299</td>\n",
       "      <td>1237</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How do you all cope with OCD and live on?</td>\n",
       "      <td>life, coping with OCD</td>\n",
       "      <td>yy5ja0</td>\n",
       "      <td>life, coping with OCD How do you all cope with...</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I’ll try to make this as concise as possible, ...</td>\n",
       "      <td>Existential OCD, and fear of Psychosis OCD?</td>\n",
       "      <td>yy4vb3</td>\n",
       "      <td>Existential OCD, and fear of Psychosis OCD? I’...</td>\n",
       "      <td>1599</td>\n",
       "      <td>1555</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I suffer from many different kinds of OCD and ...</td>\n",
       "      <td>OCD is ruining my life and can potentially rui...</td>\n",
       "      <td>yy4v6r</td>\n",
       "      <td>OCD is ruining my life and can potentially rui...</td>\n",
       "      <td>195</td>\n",
       "      <td>138</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Last night I went to see Black Panther 2 with ...</td>\n",
       "      <td>Do the exposure, babe!</td>\n",
       "      <td>yy4qs8</td>\n",
       "      <td>Do the exposure, babe! Last night I went to se...</td>\n",
       "      <td>503</td>\n",
       "      <td>480</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          0  I'll go first, I'm 28F. I have a lot of childh...   \n",
       "1          0          How do you all cope with OCD and live on?   \n",
       "2          0  I’ll try to make this as concise as possible, ...   \n",
       "3          0  I suffer from many different kinds of OCD and ...   \n",
       "4          0  Last night I went to see Black Panther 2 with ...   \n",
       "\n",
       "                                               title      id  \\\n",
       "0  What are your most disturbing/ disgusting intr...  yy5m0e   \n",
       "1                              life, coping with OCD  yy5ja0   \n",
       "2        Existential OCD, and fear of Psychosis OCD?  yy4vb3   \n",
       "3  OCD is ruining my life and can potentially rui...  yy4v6r   \n",
       "4                             Do the exposure, babe!  yy4qs8   \n",
       "\n",
       "                                            fulltext  fulltextlength  \\\n",
       "0  What are your most disturbing/ disgusting intr...            1299   \n",
       "1  life, coping with OCD How do you all cope with...              63   \n",
       "2  Existential OCD, and fear of Psychosis OCD? I’...            1599   \n",
       "3  OCD is ruining my life and can potentially rui...             195   \n",
       "4  Do the exposure, babe! Last night I went to se...             503   \n",
       "\n",
       "   selftextlength  titlelength  \n",
       "0            1237          116  \n",
       "1              41           22  \n",
       "2            1555           24  \n",
       "3             138           53  \n",
       "4             480           43  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_combined.shape)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['fulltext'] = df_combined['fulltext'].apply(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default NLTK stopword list\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "# add additional stopwords\n",
    "additional_stopwords = {'ocd','anxiety','social'}\n",
    "stop_words = stop_words.union(additional_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the rows where subreddit only contains stopwords\n",
    "df = df_combined\n",
    "df['fulltext'] = df['fulltext'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "The process of text normalisation aim to reduce the amount of noise in the data, through the removal of cases, punctuations, stopwords, and changing word constructions. \n",
    "\n",
    "Lemmatisation and stemming are both methods that try to bring inflated words to the same form, a process that reduces some noise in the data (e.g., from counting run, ran, and running all as different words). If processing speed is not a concern in this case due to the small size of the working corpus, lemmatisation will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\s+', gaps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = [tokenizer.tokenize(text.lower()) for text in (df['fulltext'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what disturbing disgusting intrusive thoughts ...\n",
       "1                 life coping ocd how cope ocd live on\n",
       "2    existential ocd fear psychosis ocd ill try mak...\n",
       "3    ocd ruining life potentially ruin life i suffe...\n",
       "4    do exposure babe last night i went see black p...\n",
       "Name: text_tokens, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_tokens'] = pd.DataFrame(data=[text_tokens], index=['text_tokens']).T[['text_tokens']]\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_tokens'] = df['text_tokens'].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "lems = []\n",
    "for post in df['text_tokens']:\n",
    "    tok_post = []\n",
    "    for word in post.split():\n",
    "        tok_post.append(lemmatize_text(word)[0])\n",
    "    lems.append(tok_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lem'] = lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lem'] = df['text_lem'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = []\n",
    "for post in df['text_tokens']:\n",
    "    tok_post = []\n",
    "    for word in post.split():\n",
    "        tok_post.append(p_stemmer.stem(word)) #why no issue with the lists of lists\n",
    "    stem.append(tok_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_stem'] = stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_stem'] = df['text_stem'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>fulltextlength</th>\n",
       "      <th>selftextlength</th>\n",
       "      <th>titlelength</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'll go first, I'm 28F. I have a lot of childh...</td>\n",
       "      <td>What are your most disturbing/ disgusting intr...</td>\n",
       "      <td>yy5m0e</td>\n",
       "      <td>What disturbing/ disgusting intrusive thoughts...</td>\n",
       "      <td>1299</td>\n",
       "      <td>1237</td>\n",
       "      <td>116</td>\n",
       "      <td>what disturbing disgusting intrusive thoughts ...</td>\n",
       "      <td>what disturbing disgusting intrusive thought i...</td>\n",
       "      <td>what disturb disgust intrus thought ill go fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>How do you all cope with OCD and live on?</td>\n",
       "      <td>life, coping with OCD</td>\n",
       "      <td>yy5ja0</td>\n",
       "      <td>life, coping OCD How cope OCD live on?</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>life coping ocd how cope ocd live on</td>\n",
       "      <td>life coping ocd how cope ocd live on</td>\n",
       "      <td>life cope ocd how cope ocd live on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I’ll try to make this as concise as possible, ...</td>\n",
       "      <td>Existential OCD, and fear of Psychosis OCD?</td>\n",
       "      <td>yy4vb3</td>\n",
       "      <td>Existential OCD, fear Psychosis OCD? I’ll try ...</td>\n",
       "      <td>1599</td>\n",
       "      <td>1555</td>\n",
       "      <td>24</td>\n",
       "      <td>existential ocd fear psychosis ocd ill try mak...</td>\n",
       "      <td>existential ocd fear psychosis ocd ill try mak...</td>\n",
       "      <td>existenti ocd fear psychosi ocd ill tri make c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I suffer from many different kinds of OCD and ...</td>\n",
       "      <td>OCD is ruining my life and can potentially rui...</td>\n",
       "      <td>yy4v6r</td>\n",
       "      <td>OCD ruining life potentially ruin life. I suff...</td>\n",
       "      <td>195</td>\n",
       "      <td>138</td>\n",
       "      <td>53</td>\n",
       "      <td>ocd ruining life potentially ruin life i suffe...</td>\n",
       "      <td>ocd ruining life potentially ruin life i suffe...</td>\n",
       "      <td>ocd ruin life potenti ruin life i suffer mani ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Last night I went to see Black Panther 2 with ...</td>\n",
       "      <td>Do the exposure, babe!</td>\n",
       "      <td>yy4qs8</td>\n",
       "      <td>Do exposure, babe! Last night I went see Black...</td>\n",
       "      <td>503</td>\n",
       "      <td>480</td>\n",
       "      <td>43</td>\n",
       "      <td>do exposure babe last night i went see black p...</td>\n",
       "      <td>do exposure babe last night i went see black p...</td>\n",
       "      <td>do exposur babe last night i went see black pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          0  I'll go first, I'm 28F. I have a lot of childh...   \n",
       "1          0          How do you all cope with OCD and live on?   \n",
       "2          0  I’ll try to make this as concise as possible, ...   \n",
       "3          0  I suffer from many different kinds of OCD and ...   \n",
       "4          0  Last night I went to see Black Panther 2 with ...   \n",
       "\n",
       "                                               title      id  \\\n",
       "0  What are your most disturbing/ disgusting intr...  yy5m0e   \n",
       "1                              life, coping with OCD  yy5ja0   \n",
       "2        Existential OCD, and fear of Psychosis OCD?  yy4vb3   \n",
       "3  OCD is ruining my life and can potentially rui...  yy4v6r   \n",
       "4                             Do the exposure, babe!  yy4qs8   \n",
       "\n",
       "                                            fulltext  fulltextlength  \\\n",
       "0  What disturbing/ disgusting intrusive thoughts...            1299   \n",
       "1             life, coping OCD How cope OCD live on?              63   \n",
       "2  Existential OCD, fear Psychosis OCD? I’ll try ...            1599   \n",
       "3  OCD ruining life potentially ruin life. I suff...             195   \n",
       "4  Do exposure, babe! Last night I went see Black...             503   \n",
       "\n",
       "   selftextlength  titlelength  \\\n",
       "0            1237          116   \n",
       "1              41           22   \n",
       "2            1555           24   \n",
       "3             138           53   \n",
       "4             480           43   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  what disturbing disgusting intrusive thoughts ...   \n",
       "1               life coping ocd how cope ocd live on   \n",
       "2  existential ocd fear psychosis ocd ill try mak...   \n",
       "3  ocd ruining life potentially ruin life i suffe...   \n",
       "4  do exposure babe last night i went see black p...   \n",
       "\n",
       "                                            text_lem  \\\n",
       "0  what disturbing disgusting intrusive thought i...   \n",
       "1               life coping ocd how cope ocd live on   \n",
       "2  existential ocd fear psychosis ocd ill try mak...   \n",
       "3  ocd ruining life potentially ruin life i suffe...   \n",
       "4  do exposure babe last night i went see black p...   \n",
       "\n",
       "                                           text_stem  \n",
       "0  what disturb disgust intrus thought ill go fir...  \n",
       "1                 life cope ocd how cope ocd live on  \n",
       "2  existenti ocd fear psychosi ocd ill tri make c...  \n",
       "3  ocd ruin life potenti ruin life i suffer mani ...  \n",
       "4  do exposur babe last night i went see black pa...  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['subreddit']\n",
    "X = df['text_tokens']\n",
    "X_lem = df['text_lem']\n",
    "X_stem = df['text_stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets for normal tokenized words\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060,)\n",
      "(5940,)\n",
      "(12060,)\n",
      "(5940,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.astype('U')\n",
    "X_test = X_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMMATIZATION: Split the data into the training and testing sets.\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_lem,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train2.values.astype('U')\n",
    "X_test = X_test2.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060,)\n",
      "(5940,)\n",
      "(12060,)\n",
      "(5940,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEMMING: Split the data into the training and testing sets.\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_stem,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train3.values.astype('U')\n",
    "X_test3= X_test3.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060,)\n",
      "(5940,)\n",
      "(12060,)\n",
      "(5940,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.shape)\n",
    "print(X_test3.shape)\n",
    "print(y_train3.shape)\n",
    "print(y_test3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "The basic baseline model would have an accuracy of 50% since we have the same number of posts from each subreddit (Social Anxiety and OCD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a basic vectoriser with only settings for extracting bi- and tri-grams\n",
    "#cvec = CountVectorizer(stop_words = stop_words, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', 'while', 'at', 'm', 'itself', 'because', \"mightn't\", 'if', 'some', \"don't\", \"you'll\", \"she's\", 'do', 'after', 'couldn', \"shouldn't\", 's', 'very', 'are', 't', 'mustn', 'she', \"mustn't\", 'ocd', \"that'll\", 'does', 'social', 'they', 'what', \"couldn't\", 'myself', 'yourself', 'themsel... 'down', 'have', 'both', 'you', 'he', 'a', 'wasn', 'on', 'can', 'them', 'is', \"won't\", 'did', 'don'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec = cvec.transform(X_train) \n",
    "X_test_cvec = cvec.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060, 20126)\n",
      "(5940, 20126)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cvec.shape)\n",
    "print(X_test_cvec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit(X_train2)\n",
    "X_train_cvec2 = cvec.transform(X_train2)\n",
    "X_test_cvec2 = cvec.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060, 26439)\n",
      "(5940, 26439)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cvec2.shape)\n",
    "print(X_test_cvec2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit(X_train3)\n",
    "X_train_cvec3 = cvec.transform(X_train3)\n",
    "X_test_cvec3 = cvec.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060, 20126)\n",
      "(5940, 20126)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cvec3.shape)\n",
    "print(X_test_cvec3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Metric used for model evaluation: $F_1$-score\n",
    "\n",
    "The key metric we are using to evaluate the model is 'f1_score'. In this classification problem, we neither want to minimize false positives or negatives as both mental health conditions are equally important and we wish\n",
    "\n",
    "Instead of using 'Recall' or 'Precision', using 'f1_score' balances our false positives and false negatives. As either false positives or false negatives increase, the denominator increases while the numerator stays fixed, meaning our $F_1$-score decreases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for F1 score\n",
    "\n",
    "def f1_scorer(model, X_train, X_test, y_train, y_test):\n",
    "    f1_train = f1_score(y_true = y_train,\n",
    "                        y_pred = model.predict(X_train))\n",
    "    f1_test = f1_score(y_true = y_test,\n",
    "                       y_pred = model.predict(X_test))\n",
    "    \n",
    "    print(\"The training F1-score for \" + str(model.__class__.__name__) + \" is: \" + str(f1_train))\n",
    "    print(\"The testing F1-score for \" + str(model.__class__.__name__) + \" is: \" + str(f1_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest for a Binary Classification Problem:\n",
    "\n",
    "Random forest decorrelates the trees in decision trees from one another. By loooking at the randomly selected subset of the features (X variables), Random forest results in higher bias, lower variance. As the Random Forest method limits the allowed variables to split on in each node, the bias for a single random forest tree is increased even more.\n",
    "\n",
    "In Random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.1 RF with normal tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893864013266999"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "cross_val_score(rf, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9986733001658374\n",
      "Score on testing set: 0.8915824915824916\n"
     ]
    }
   ],
   "source": [
    "print(f'Score on training set: {rf.score(X_train, y_train)}')\n",
    "print(f'Score on testing set: {rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc training set:  0.952678426551598\n",
      "roc auc test set :  0.8883838383838384\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(rf, X_train, y_train, cv=5, scoring = 'roc_auc')\n",
    "print('roc auc training set: ', np.mean(accuracies))\n",
    "print('roc auc test set : ', metrics.roc_auc_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model $F_1$-score with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for RandomForestClassifier is: 0.9986741796486576\n",
      "The testing F1-score for RandomForestClassifier is: 0.8871489361702127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scorer(model_rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Gridsearch to fine tune the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_params = {\n",
    "    'cvec__max_features': [2_000, 3_000],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [None, 1, 2],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid = pipe_rf_params, \n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'rf__n_estimators': [100, 200], 'rf__max_depth': [None, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932835820895523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': None, 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_rf.best_score_)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000], 'cvec__ngram_range': [(1, 1), (1, 2)], 'rf__n_estimators': [100, 200], 'rf__max_depth': [None, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905472636815921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_rf.best_score_)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change model parameters to optimal ones found during GridSearch\n",
    "pipe_rf_gs = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words, ngram_range= (1, 2), max_features= 3000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf1 = pipe_rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate $F_1$-score after tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9981776010603048\n",
      "The testing F1-score for Pipeline is: 0.8898633833698769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scorer(model_rf1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing F1-score only improved slightly after tuning to 0.890 (rounded) from 0.8871 (before tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.2 RF with Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000], 'cvec__ngram_range': [(1, 1), (1, 2)], 'rf__n_estimators': [100, 200], 'rf__max_depth': [None, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889469320066335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_rf.best_score_)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change model parameters to optimal ones found during GridSearch (no change from previous)\n",
    "pipe_rf_gs = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words, ngram_range= (1, 2), max_features= 3000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf2 = pipe_rf_gs.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9981776010603048\n",
      "The testing F1-score for Pipeline is: 0.8862639217009788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scorer(model_rf2, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.3 RF with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000], 'cvec__ngram_range': [(1, 1), (1, 2)], 'rf__n_estimators': [100, 200], 'rf__max_depth': [None, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014096185737976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_rf.best_score_)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change model parameters to optimal ones found during GridSearch (no change from previous)\n",
    "pipe_rf_gs3 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words, ngram_range= (1, 1), max_features= 3000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_rf3 = pipe_rf_gs3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9985084521047397\n",
      "The testing F1-score for Pipeline is: 0.8978759558198811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf3 = pipe_rf_gs3.fit(X_train3, y_train3)\n",
    "f1_scorer(model_rf3, X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:\n",
    "\n",
    "Random Forest models are prone to overfitting.\n",
    "We choose Model 1.3 - Random Forest using stemming as it produces highest testing f1-score of 0.90 (rounded up), which has n-gram range of (1,1) unlike the other 2 models which has n-gram range of (1,2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted r/social anxiety</th>\n",
       "      <th>predicted r/ocd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual r/social anxiety</th>\n",
       "      <td>2697</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual r/ocd</th>\n",
       "      <td>328</td>\n",
       "      <td>2642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted r/social anxiety  predicted r/ocd\n",
       "actual r/social anxiety                        2697              273\n",
       "actual r/ocd                                    328             2642"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model_rf3.predict(X_test3) \n",
    "# print confusion matrix\n",
    "cmatrix = confusion_matrix(y_test3, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "pd.DataFrame(cmatrix, \n",
    "             index = ['actual r/social anxiety','actual r/ocd'],\n",
    "             columns = ['predicted r/social anxiety', 'predicted r/ocd'])\n",
    "# tn, fp, \n",
    "# fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "Naive Bayes is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "\n",
    "This model shortens the time taken for training. We use this as a comparison to see whether model performance is improved from the Random Forest model used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.1 Naive Bayes with normal Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words)),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "gs_nb = GridSearchCV(pipe_nb,\n",
    "                  param_grid = pipe_nb_params, \n",
    "                  cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...kenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000, 4000, 5000], 'cvec__min_df': [2, 3], 'cvec__max_df': [0.9, 0.95], 'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072139303482587\n"
     ]
    }
   ],
   "source": [
    "print(gs_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072139303482587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_nb.best_score_)\n",
    "gs_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change model parameters to optimal ones found during GridSearch \n",
    "pipe_nb_gs = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words, ngram_range= (1, 1), max_features= 5000, max_df = 0.9, min_df = 3)),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb1 = pipe_rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9981776010603048\n",
      "The testing F1-score for Pipeline is: 0.888288896388795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_scorer(model_nb1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.2  Naive Bayes with Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb2 = GridSearchCV(pipe_nb,\n",
    "                  param_grid = pipe_nb_params, \n",
    "                  cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...kenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000, 4000, 5000], 'cvec__min_df': [2, 3], 'cvec__max_df': [0.9, 0.95], 'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_nb2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072139303482587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_nb2.best_score_)\n",
    "gs_nb2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change model parameters to optimal ones found during GridSearch (no change from previous)\n",
    "pipe_nb_gs = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stop_words, ngram_range= (1, 1), max_features= 5000, max_df = 0.9, min_df = 3)),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9981779029319199\n",
      "The testing F1-score for Pipeline is: 0.8883650446203065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nb2 = pipe_rf_gs.fit(X_train2, y_train2)\n",
    "f1_scorer(model_nb2, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.3  Naive Bayes with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb3 = GridSearchCV(pipe_nb,\n",
    "                  param_grid = pipe_nb_params, \n",
    "                  cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'haven', '...kenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cvec__max_features': [2000, 3000, 4000, 5000], 'cvec__min_df': [2, 3], 'cvec__max_df': [0.9, 0.95], 'cvec__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_nb3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9077943615257048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_nb3.best_score_)\n",
    "gs_nb3.best_params_\n",
    "#Again, no difference in best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9985082048731975\n",
      "The testing F1-score for Pipeline is: 0.8975229046487954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nb3 = pipe_rf_gs.fit(X_train3, y_train3)\n",
    "f1_scorer(model_nb3, X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score\n",
    "print('For Naive Bayes Model with Stemming')\n",
    "print(f'Score on training set: {model_nb3.score(X_train3, y_train3)}')\n",
    "print(f'Score on testing set: {model_nb3.score(X_test3, y_test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted r/social anxiety</th>\n",
       "      <th>predicted r/ocd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual r/social anxiety</th>\n",
       "      <td>2691</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual r/ocd</th>\n",
       "      <td>325</td>\n",
       "      <td>2645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted r/social anxiety  predicted r/ocd\n",
       "actual r/social anxiety                        2691              279\n",
       "actual r/ocd                                    325             2645"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model_nb3.predict(X_test3) #If using lemmmatization, change to X_test2 or X_test3 for stemming\n",
    "# print confusion matrix\n",
    "cmatrix = confusion_matrix(y_test3, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "pd.DataFrame(cmatrix, \n",
    "             index = ['actual r/social anxiety','actual r/ocd'],\n",
    "             columns = ['predicted r/social anxiety', 'predicted r/ocd'])\n",
    "# tn, fp, \n",
    "# fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Comparison of final model using CountVectorizer with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Gridsearch parameters that were optimal for Countvectorizer, only switching out the vectorizer to TF-IDF vectorizer\n",
    "pipe_rf_extension = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(stop_words = stop_words, ngram_range= (1, 1), max_features= 3000)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance based on the key metric, F1-score, is better using TF-IDF than CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training F1-score for Pipeline is: 0.9985086992543496\n",
      "The testing F1-score for Pipeline is: 0.9009345794392524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf4 = pipe_rf_extension.fit(X_train3, y_train3)\n",
    "f1_scorer(model_rf4, X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted r/social anxiety</th>\n",
       "      <th>predicted r/ocd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual r/social anxiety</th>\n",
       "      <td>2706</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual r/ocd</th>\n",
       "      <td>319</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted r/social anxiety  predicted r/ocd\n",
       "actual r/social anxiety                        2706              264\n",
       "actual r/ocd                                    319             2651"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model_rf4.predict(X_test3) \n",
    "# print confusion matrix\n",
    "cmatrix = confusion_matrix(y_test3, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "pd.DataFrame(cmatrix, \n",
    "             index = ['actual r/social anxiety','actual r/ocd'],\n",
    "             columns = ['predicted r/social anxiety', 'predicted r/ocd'])\n",
    "# tn, fp, \n",
    "# fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of models:\n",
    "The final model chosen for this classification problem is: Random Forest using Stemming, with TF-IDF Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the TF-IDF Vectorizer in place of CountVectorizer improves the accuracy and F1 score only slightly, and all models are overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension: Visualisation of top words and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training data to dataframe\n",
    "X_train_df = pd.DataFrame(tvec.fit_transform(X_train).todense(), \n",
    "                          columns=tvec.get_feature_names())\n",
    "\n",
    "# plot top occuring words\n",
    "X_train_df.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 words\n",
    "X_train_df = pd.DataFrame(X_train, #what is .todense?\n",
    "                          columns=cvec.get_feature_names())\n",
    "\n",
    "# plot top occuring words\n",
    "X_train_df.sum().sort_values(ascending=False).head(10).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_trigrams = CountVectorizer(ngram_range=(3, 3), stop_words=stop_words)\n",
    "cv_trigrams.fit(X_train2)#df['text_lem'])\n",
    "\n",
    "trigrams_cv = cv_trigrams.transform(X_train2) #df['text_lem'])\n",
    "trigrams_df = pd.DataFrame(trigrams_cv.todense(), columns=cv_trigrams.get_feature_names())\n",
    "\n",
    "trigrams_df.sum().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#For Future Reference only: sample codes to iterate through all \n",
    "\n",
    "# create pipeline to check both vectorisers\n",
    "pl = Pipeline([\n",
    "    # select the 'title' column\n",
    "    ('selector', FunctionTransformer(lambda x:x['title'], validate=False)),  \n",
    "    # vectorizers (and all pipeline steps below) will be specified in the param_grid\n",
    "    ('vectorizer', None),                                                   \n",
    "    ('reducer', None),\n",
    "    ('binarizer', None),\n",
    "    ('classifier', None)\n",
    "])\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "param_grid = [{\n",
    "        # vectorisers to try: count vectoriser, tf-idf vectoriser\n",
    "        'vectorizer': [CountVectorizer(tokenizer = spacy_tokenizer, stop_words = stop_words, ngram_range = (1,3)),\n",
    "                       TfidfVectorizer(tokenizer = spacy_tokenizer, stop_words = stop_words, ngram_range = (1,3))],\n",
    "        # feature selection by max df\n",
    "        'vectorizer__max_df': [1, 0.05, 0.1],\n",
    "\n",
    "        # to binarise or not to binarise\n",
    "        'binarizer': [None,\n",
    "                     Binarizer()],\n",
    "        # models to test: multinomial Naive Bayes and logistic regression\n",
    "        'classifier': [MultinomialNB(), RandomForestClassifier()]\n",
    "    }]\n",
    "\n",
    "# use kfold for cv to allow shuffling\n",
    "kf = KFold(n_splits = 2, shuffle = True, random_state = 7)\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_title = GridSearchCV(pl, cv=kf, param_grid=param_grid, scoring = 'accuracy', iid=False, verbose=True)\n",
    "gs_title.fit(xtrain, ytrain)\n",
    "ypred_title = gs_title.predict(xval)\n",
    "\n",
    "# call .score on the gs object to use the best parameters found during gridsearch to evaluate train and val \n",
    "print('train accuracy:', gs_title.score(xtrain, ytrain))\n",
    "print('validation set accuracy:', gs_title.score(xval, yval))\n",
    "print(gs_title.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
